{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835bbdd4-f8f1-4c2e-a890-6bf4d979d0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    import torch\n",
    "    import random\n",
    "    import numpy as np\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f807cb-0a9c-47e4-b514-17135b46bcaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertConfig, BertForMaskedLM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406bcc51-95c5-4d53-b272-a58e2b3c2911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amino_acids = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"  # Standard amino acids\n",
    "vocab = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "vocab[\"[MASK]\"] = len(vocab)  # Add special [MASK] token\n",
    "vocab[\"[PAD]\"] = len(vocab)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9a4143-b3d7-4779-88c4-1859aa9c20bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.fft import rfft, irfft\n",
    "from einops import rearrange\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "\n",
    "class DiscreteTransform(nn.Module):\n",
    "    def __init__(self, mode=\"fft\", dim=-1):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == \"fft\":\n",
    "            #print(f\"fft {x.shape}\")\n",
    "            return rfft(x, dim=self.dim)\n",
    "\n",
    "    def inverse(self, x, original_size=None):\n",
    "        if self.mode == \"fft\":\n",
    "            return irfft(x, dim=self.dim, n=original_size)\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        input_shape = input_ids.size()\n",
    "        seq_length = input_shape[1]\n",
    "\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "        word_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = word_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings  \n",
    "\n",
    "class StaticConv(nn.Module):\n",
    "    def __init__(self, d_model, seq_len):\n",
    "        super().__init__()\n",
    "        self.positional_encoding = nn.Parameter(\n",
    "            torch.zeros(seq_len, d_model), requires_grad=False  # Non-learnable zeros\n",
    "        )\n",
    "\n",
    "    def forward(self, batch_size):\n",
    "        # Expand positional encodings to include the batch dimension\n",
    "        batch_positional_encoding = self.positional_encoding.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        return batch_positional_encoding\n",
    "\n",
    "\n",
    "class Abs(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.abs(x)\n",
    "    \n",
    "class OrchidOperator(nn.Module):\n",
    "    def __init__(self, d, seq_len, d_filter=64, l_conv1d=3, transform_mode=\"fft\"):\n",
    "        super().__init__()\n",
    "        self.d_model = d\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.in_linear = nn.Linear(d, 3 * d)\n",
    "        self.out_linear = nn.Linear(d, d)\n",
    "\n",
    "        width = d * 3\n",
    "        self.short_filter = nn.Conv1d(width , width , kernel_size = l_conv1d , groups =width , padding = l_conv1d // 2)        \n",
    "       \n",
    "        self.static_conv = StaticConv(d, seq_len)\n",
    "        #self.static_conv = StaticConv(d, d_filter, seq_len)\n",
    "\n",
    "        self.conditioning_nn = nn.Sequential(\n",
    "            nn.Conv1d(d, d, kernel_size = l_conv1d, padding=l_conv1d // 2, groups=d),\n",
    "            DiscreteTransform(mode=transform_mode, dim=-1),\n",
    "            Abs(),\n",
    "            nn.Conv1d(d, d, kernel_size = l_conv1d, padding=l_conv1d // 2, groups=d),\n",
    "        )\n",
    "\n",
    "        self.transform = DiscreteTransform(mode=transform_mode, dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, seq_len, dim = x.size()\n",
    "        orig_x = x\n",
    "\n",
    "        x = self.in_linear(x)\n",
    "        x = nn.functional.gelu(x)\n",
    "        #_, _, v = torch.split(x, dim, dim=-1)\n",
    "        _, _, v = x.split(self.d_model, dim=-1)\n",
    "        #print(v.shape)\n",
    "\n",
    "        h_adapt_f = self.conditioning_nn(rearrange(v, \"b l d -> b d l\"))\n",
    "        \n",
    "        h_static = self.static_conv(batch).transpose(1, 2)\n",
    "\n",
    "        x = rearrange(x, \"b l d -> b d l\")\n",
    "        x = self.short_filter(x)[..., : self.seq_len]\n",
    "        s1, s2, v = x.split(self.d_model, dim=1)\n",
    "\n",
    "        y = v * s1\n",
    "        y = self.adaptive_conv(y, h_static, h_adapt_f)\n",
    "        y = y * s2\n",
    "        y = rearrange(y, \"b d l -> b l d\")\n",
    "        y = self.out_linear(y)\n",
    "        y = nn.functional.gelu(y)\n",
    "\n",
    "        return self.out_linear(y)\n",
    "\n",
    "    def adaptive_conv(self, x, h_static, h_adapt_f):\n",
    "        x_seq_len = x.shape[-1]\n",
    "        h_static_f = self.transform(h_static)\n",
    "        x_f = self.transform(x)\n",
    "        \n",
    "        #print(f\"self seq {self.seq_len}, h_static_f {h_static_f.shape}, h_adapt_f {h_adapt_f.shape},  x_f { x_f.shape},  h_static {h_static.shape}, x {x.shape}\")\n",
    "        \n",
    "        y = self.transform.inverse(x_f * (h_static_f[:,:,:h_adapt_f.shape[-1]] + h_adapt_f),original_size=x_seq_len)\n",
    "        _ = x_f * (h_static_f[:,:,:h_adapt_f.shape[-1]] + h_adapt_f)\n",
    "        #print(f\"y {y.shape}, before inverse {_.shape}\")\n",
    "        #return y[..., : self.seq_len]\n",
    "        return y[..., : x_seq_len]\n",
    "        \n",
    "\n",
    "class OrchidBertLayer(nn.Module):\n",
    "    def __init__(self, config, seq_len, l_conv1d):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.orchid = OrchidOperator(\n",
    "            d=config.hidden_size,\n",
    "            seq_len=seq_len,\n",
    "            d_filter=64,  # Adjust as needed\n",
    "            l_conv1d=l_conv1d,   # Adjust as needed\n",
    "            transform_mode=\"fft\"\n",
    "        )\n",
    "        self.intermediate = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.output = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout1 = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(config.hidden_dropout_prob)\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        # Pass hidden_states and positional embeddings to Orchid layer\n",
    "        orchid_output = self.orchid(hidden_states)\n",
    "        hidden_states = hidden_states + self.dropout1(orchid_output)\n",
    "        hidden_states = self.norm1(hidden_states)\n",
    "\n",
    "        # Feedforward block\n",
    "        intermediate_output = self.intermediate(hidden_states)\n",
    "        intermediate_output = nn.functional.gelu(intermediate_output)\n",
    "        layer_output = self.output(intermediate_output)\n",
    "        hidden_states = hidden_states + self.dropout2(layer_output)\n",
    "        hidden_states = self.norm2(hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "class OrchidBERT(nn.Module):\n",
    "    def __init__(self, config, seq_len, l_conv1d):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [OrchidBertLayer(config, seq_len, l_conv1d) for _ in range(config.num_hidden_layers)]\n",
    "        )\n",
    "        self.cls_head = nn.Linear(config.hidden_size, config.vocab_size)  # For Masked LM\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Compute embeddings\n",
    "        embeddings = self.embeddings(input_ids)\n",
    "        #position_embeddings = self.embeddings.position_embeddings.weight.unsqueeze(0)\n",
    "        hidden_states = embeddings\n",
    "\n",
    "        # Apply attention mask to embeddings if needed\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.unsqueeze(-1)  # Match embedding dimensions\n",
    "            hidden_states = hidden_states * attention_mask\n",
    "        \n",
    "        \n",
    "        # Pass through Orchid-enhanced Transformer layers\n",
    "        for layer in self.encoder_layers:\n",
    "            #hidden_states = layer(hidden_states, position_embeddings)\n",
    "            hidden_states = layer(hidden_states)\n",
    "\n",
    "        logits = self.cls_head(hidden_states)\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        return MaskedLMOutput(\n",
    "            loss=None,\n",
    "            logits=probs,\n",
    "            hidden_states=[hidden_states],  # Optionally return hidden states if needed\n",
    "            attentions=None      # Optionally return attentions if needed\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b413a060-3621-4753-a388-5c9a7ad237ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FineTunedOrchidModel(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_targets, task_type=\"classification\"):\n",
    "        super(FineTunedOrchidModel, self).__init__()\n",
    "        self.pretrained_model = pretrained_model  # Orchid-BERT\n",
    "        self.task_type = task_type\n",
    "        self.output_dim = num_targets\n",
    "        \n",
    "        # Task-specific head\n",
    "        if self.task_type == \"classification\":\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(pretrained_model.config.hidden_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, self.output_dim),\n",
    "                #nn.Softmax(dim=1)\n",
    "            )\n",
    "        elif self.task_type == \"regression\":\n",
    "            self.head = nn.Sequential(\n",
    "                \n",
    "                nn.Conv1d(pretrained_model.config.hidden_size, 128, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveMaxPool1d(1),  # Outputs a single vector for each sequence\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(128, 128),\n",
    "                \n",
    "                #nn.Linear(pretrained_model.config.hidden_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, self.output_dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Forward pass through Orchid-BERT\n",
    "        outputs = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.hidden_states[-1]# CLS token embedding\n",
    "        \n",
    "        if self.task_type == \"regression\": \n",
    "            #pooled_output = pooled_output[:, 0, :]\n",
    "            #pooled_output = pooled_output.mean(dim=1)\n",
    "            pooled_output = pooled_output.transpose(1, 2)\n",
    "        return self.head(pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b4cae1-4d4f-411e-b16d-6de51434ca0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, data, max_len, pad_token=\"[PAD]\", task_type=\"classification\"):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "        self.pad_token = pad_token\n",
    "        self.task_type = task_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, targets = self.data[idx]\n",
    "        \n",
    "        #print(len(input_ids),len(targets))\n",
    "\n",
    "        # Pad input_ids to max_len\n",
    "        padding_length = self.max_len - len(input_ids)\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + [vocab[self.pad_token]] * padding_length\n",
    "        \n",
    "        attention_mask = [1] * (self.max_len - padding_length) + [0] * padding_length\n",
    "\n",
    "        # Adjust targets for each task\n",
    "        if self.task_type == \"classification\":\n",
    "            targets = targets + [-100] * padding_length  # For sequence tasks (secondary structure)\n",
    "        elif self.task_type == \"regression\":\n",
    "            targets = torch.tensor(targets, dtype=torch.float)  # For scalar tasks (fluorescence)\n",
    "\n",
    "        #print(len(input_ids),len(targets),len(attention_mask))\n",
    "        return (\n",
    "            torch.tensor(input_ids),\n",
    "            torch.tensor(targets),\n",
    "            torch.tensor(attention_mask)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea9ac08-4f4f-4be3-b38e-929288ff32e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "def train(model, train_loader, val_loader, save_path, epochs=20, patience=3, task_type=\"classification\"):\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "    \n",
    "    # Loss function selection\n",
    "    if task_type == \"classification\":\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=-100)  # Secondary structure\n",
    "    elif task_type == \"regression\":\n",
    "        criterion = nn.MSELoss()  # Fluorescence\n",
    "\n",
    "    train_metrics, val_metrics = [], []\n",
    "    spearman_metrics = []  # For regression tasks\n",
    "    best_val_loss = float(\"inf\")\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss, total_metric, total = 0, 0, 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "            input_ids, targets, attention_mask = (\n",
    "                batch[0].to(device),\n",
    "                batch[1].to(device),\n",
    "                batch[2].to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            if task_type == \"classification\":\n",
    "                logits = outputs\n",
    "                #print(logits.shape, targets.shape)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "                predictions = logits.argmax(dim=-1)\n",
    "                total_metric += (predictions == targets).sum().item()\n",
    "                total += (targets != -100).sum().item()\n",
    "            elif task_type == \"regression\":\n",
    "                predictions = outputs.squeeze()\n",
    "                loss = criterion(predictions, targets)\n",
    "                total_metric += ((predictions - targets) ** 2).sum().item()  # MSE calculation\n",
    "                total += len(targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_metrics.append(total_metric / total)  # Accuracy for classification, MSE for regression\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, total_metric, total = 0, 0, 0\n",
    "        all_predictions, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}\"):\n",
    "                input_ids, targets, attention_mask = (\n",
    "                    batch[0].to(device),\n",
    "                    batch[1].to(device),\n",
    "                    batch[2].to(device),\n",
    "                )\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                if task_type == \"classification\":\n",
    "                    logits = outputs\n",
    "                    loss = criterion(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "                    predictions = logits.argmax(dim=-1)\n",
    "                    total_metric += (predictions == targets).sum().item()\n",
    "                    total += (targets != -100).sum().item()\n",
    "                elif task_type == \"regression\":\n",
    "                    predictions = outputs.squeeze()\n",
    "                    loss = criterion(predictions, targets)\n",
    "                    total_metric += ((predictions - targets) ** 2).sum().item()  # MSE calculation\n",
    "                    total += len(targets)\n",
    "                    all_predictions.extend(predictions.cpu().numpy())\n",
    "                    all_targets.extend(targets.cpu().numpy())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_metrics.append(total_metric / total)  # Accuracy for classification, MSE for regression\n",
    "        \n",
    "        if task_type == \"regression\":\n",
    "            # Compute Spearman correlation\n",
    "            spearman_corr, _ = spearmanr(all_predictions, all_targets)\n",
    "            spearman_metrics.append(spearman_corr)\n",
    "            print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
    "\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}: Train Metric={train_metrics[-1]:.4f}, Val Metric={val_metrics[-1]:.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"Saving model with Val Loss={val_loss:.4f}\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stop_counter = early_stop_counter + 1 if val_loss > best_val_loss else 0\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "\n",
    "    return train_metrics, val_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe8e735-5eac-46ec-b31a-ed6d787131aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, task_type=\"classification\"):\n",
    "    model.eval()\n",
    "    correct, total, total_metric = 0, 0, 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100) if task_type == \"classification\" else nn.MSELoss()\n",
    "    all_predictions, all_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            input_ids, targets, attention_mask = (\n",
    "                batch[0].to(device),\n",
    "                batch[1].to(device),\n",
    "                batch[2].to(device),\n",
    "            )\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            if task_type == \"classification\":\n",
    "                logits = outputs\n",
    "                predictions = logits.argmax(dim=-1)\n",
    "                total_metric += (predictions == targets).sum().item()\n",
    "                total += (targets != -100).sum().item()\n",
    "            elif task_type == \"regression\":\n",
    "                predictions = outputs.squeeze()\n",
    "                total_metric += ((predictions - targets) ** 2).sum().item()  # Sum of squared errors\n",
    "                total += len(targets)\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "    if task_type == \"regression\":\n",
    "        # Compute Spearman correlation\n",
    "        spearman_corr, _ = spearmanr(all_predictions, all_targets)\n",
    "        #spearman_metrics.append(spearman_corr)\n",
    "        print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
    "\n",
    "    if task_type == \"classification\":\n",
    "        accuracy = total_metric / total\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        return accuracy\n",
    "    elif task_type == \"regression\":\n",
    "        mse = total_metric / total  # Mean Squared Error\n",
    "        print(f\"Test MSE: {mse:.4f}\")\n",
    "        return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663fdd77-8877-40e5-9834-0e66267588ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import os \n",
    "import json\n",
    "import pickle\n",
    "\n",
    "base_path = os.getcwd()\n",
    "#path = os.path.join(base_path, \"fluorescence\", \"fluorescence_test.lmdb\")\n",
    "# Path to the LMDB folder (not the .mdb file)\n",
    "# Path to the LMDB folder (not the .mdb file itself)\n",
    "\n",
    "def load_fluorescence_data(path):\n",
    "    lmdb_path = os.path.join(base_path,path)\n",
    "\n",
    "    # Open the LMDB environment\n",
    "    env = lmdb.open(lmdb_path, readonly=True)\n",
    "\n",
    "    # List to store the extracted data\n",
    "    data_list = []\n",
    "\n",
    "    # Start a transaction to read data\n",
    "    with env.begin() as txn:\n",
    "        cursor = txn.cursor()\n",
    "        for key, value in cursor:\n",
    "            # Decode the key and value (adjust decoding as needed)\n",
    "            decoded_key = key.decode(\"utf-8\")\n",
    "            decoded_value = pickle.loads(value)\n",
    "            data_list.append((decoded_key, decoded_value))  # Store as (key, value) tuples\n",
    "\n",
    "    print(f\"Total entries: {len(data_list)}\")\n",
    "    #print(f\"Sample entry: {data_list[0]}\")\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ddbe7d-0e7d-4ae9-90d5-a69e82a14cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 21447\n",
      "Total entries: 27218\n",
      "Total entries: 5363\n"
     ]
    }
   ],
   "source": [
    "fluorescence_data = {}\n",
    "_keys = [\"train\", \"test\", \"val\"]\n",
    "fluorescence_paths = [\"fluorescence/fluorescence_train.lmdb\",\"fluorescence/fluorescence_test.lmdb\",\"fluorescence/fluorescence_valid.lmdb\"]\n",
    "fluorescence_input_label_pairs = {}\n",
    "\n",
    "for key, path in zip(_keys, fluorescence_paths):\n",
    "    # Load the data for the given key (train, test, val)\n",
    "    fluorescence_data[key] = load_fluorescence_data(path)\n",
    "    \n",
    "    # Initialize the input-label pairs list for the given key\n",
    "    fluorescence_input_label_pairs[key] = []\n",
    "\n",
    "    # Process each data entry\n",
    "    for entry in fluorescence_data[key][:-1]:\n",
    "        # Extract the primary sequence and labels (ss3)\n",
    "        primary_sequence = list(entry[1][\"primary\"])\n",
    "        labels = entry[1][\"log_fluorescence\"][0]\n",
    "\n",
    "        # Convert primary sequence to token IDs using the vocabulary\n",
    "        inp_ids = [vocab[tok] for tok in primary_sequence]\n",
    "\n",
    "        # Append the input-label pair to the list\n",
    "        fluorescence_input_label_pairs[key].append((inp_ids, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485ce685-1dca-4f4e-ac86-5a59d646565a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 8679\n",
      "Total entries: 514\n",
      "Total entries: 2171\n"
     ]
    }
   ],
   "source": [
    "secondary_structure_data = {}\n",
    "secondary_structure_input_label_pairs = {}\n",
    "_keys = [\"train\", \"test\", \"val\"]\n",
    "secondary_structure_paths = [\"secondary_structure/secondary_structure_train.lmdb\",\"secondary_structure/secondary_structure_cb513.lmdb\",\"secondary_structure/secondary_structure_valid.lmdb\"]\n",
    "\n",
    "for key, path in zip(_keys, secondary_structure_paths):\n",
    "    # Load the data for the given key (train, test, val)\n",
    "    secondary_structure_data[key] = load_fluorescence_data(path)\n",
    "    \n",
    "    # Initialize the input-label pairs list for the given key\n",
    "    secondary_structure_input_label_pairs[key] = []\n",
    "\n",
    "    # Process each data entry\n",
    "    for entry in secondary_structure_data[key][:-1]:\n",
    "        # Extract the primary sequence and labels (ss3)\n",
    "        primary_sequence = list(entry[1][\"primary\"])\n",
    "        labels = entry[1][\"ss3\"].tolist()\n",
    "\n",
    "        # Convert primary sequence to token IDs using the vocabulary\n",
    "        inp_ids = [vocab[tok] for tok in primary_sequence]\n",
    "\n",
    "        # Append the input-label pair to the list\n",
    "        secondary_structure_input_label_pairs[key].append((inp_ids, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d3ce5f3-e038-4852-a1a7-508ef714ed82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_test(task_type, train_data, val_data, test_data, seq_len, vocab, model_class, pretrained_model_path, output_model_path, num_targets=1,skip=[]):\n",
    "    \"\"\"\n",
    "    Train and test a model for a given task type.\n",
    "\n",
    "    Parameters:\n",
    "        task_type (str): Task type, either \"regression\" or \"classification\".\n",
    "        train_data (list): Training dataset.\n",
    "        val_data (list): Validation dataset.\n",
    "        test_data (list): Test dataset.\n",
    "        seq_len (int): Sequence length to filter data and configure the model.\n",
    "        vocab (dict): Vocabulary mapping.\n",
    "        model_class (torch.nn.Module): The model class to be used.\n",
    "        pretrained_model_path (str): Path to the pretrained model file.\n",
    "        output_model_path (str): Path to save the fine-tuned model.\n",
    "        num_targets (int): Number of output targets for the task.\n",
    "\n",
    "    Returns:\n",
    "        float: Test accuracy or metric after testing the model.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    cut_len = 10000000000\n",
    "    \n",
    "    # Filter data based on sequence length\n",
    "    train_data = [item for item in train_data if len(item[0]) <= seq_len][:cut_len]\n",
    "    val_data = [item for item in val_data if len(item[0]) <= seq_len][:cut_len]\n",
    "    test_data = [item for item in test_data if len(item[0]) <= seq_len][:cut_len]\n",
    "    \n",
    "    old_seq_len = seq_len\n",
    "    seq_len = max([len(item[0]) for item in train_data+val_data+test_data])\n",
    "\n",
    "    # Prepare DataLoaders\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(ProteinDataset(train_data, seq_len,task_type=task_type), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(ProteinDataset(val_data, seq_len,task_type=task_type), batch_size=batch_size)\n",
    "    test_loader = DataLoader(ProteinDataset(test_data, seq_len,task_type=task_type), batch_size=batch_size)\n",
    "\n",
    "    # Configure device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load pretrained model\n",
    "    config = BertConfig(\n",
    "        vocab_size=len(vocab),\n",
    "        hidden_size=128,\n",
    "        num_hidden_layers=3,\n",
    "        num_attention_heads=2,\n",
    "        intermediate_size=256,\n",
    "        hidden_dropout_prob=0.1,\n",
    "        max_position_embeddings=old_seq_len,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "\n",
    "    if model_class == OrchidBERT:\n",
    "        pretrained_model = model_class(config, seq_len=old_seq_len, l_conv1d=11)\n",
    "    else:\n",
    "        pretrained_model = model_class(config)\n",
    "    pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "    pretrained_model.to(device)\n",
    "\n",
    "    if output_model_path not in skip:\n",
    "        # Initialize task-specific model\n",
    "        model = FineTunedOrchidModel(pretrained_model, num_targets=num_targets, task_type=task_type)\n",
    "        model.to(device)\n",
    "\n",
    "        # Train the model\n",
    "        print(f\"Training model for task: {task_type}, sequence length: {seq_len}, pretrain model: {pretrained_model_path}\")\n",
    "        train(model, train_loader, val_loader, output_model_path, task_type=task_type)\n",
    "    \n",
    "    model = FineTunedOrchidModel(pretrained_model, num_targets=num_targets, task_type=task_type)\n",
    "    model.load_state_dict(torch.load(output_model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "    # Test the model\n",
    "    test_accuracy = test(model, test_loader, task_type=task_type)\n",
    "\n",
    "    print(f\"Test Accuracy for task: {task_type} at sequence length {seq_len} pretrain model {pretrained_model_path}: {test_accuracy:.4f}\")\n",
    "\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "480287cc-e8ec-4c2c-a456-4ac07f8ce380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_84\\2904733188.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for task: regression, sequence length: 237, pretrain model: transformer_model_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|                                                                        | 0/671 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_84\\1911442212.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(targets),\n",
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.25it/s]\n",
      "Validation Epoch 1: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.4734\n",
      "Epoch 1: Train Metric=0.7197, Val Metric=0.6044, Val Loss=101.4733\n",
      "Saving model with Val Loss=101.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.26it/s]\n",
      "Validation Epoch 2: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5848\n",
      "Epoch 2: Train Metric=0.4065, Val Metric=0.3885, Val Loss=65.2444\n",
      "Saving model with Val Loss=65.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.19it/s]\n",
      "Validation Epoch 3: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6035\n",
      "Epoch 3: Train Metric=0.2911, Val Metric=0.3035, Val Loss=51.0249\n",
      "Saving model with Val Loss=51.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.27it/s]\n",
      "Validation Epoch 4: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6256\n",
      "Epoch 4: Train Metric=0.2443, Val Metric=0.2195, Val Loss=36.9322\n",
      "Saving model with Val Loss=36.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.16it/s]\n",
      "Validation Epoch 5: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6736\n",
      "Epoch 5: Train Metric=0.2112, Val Metric=0.2245, Val Loss=37.8024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.27it/s]\n",
      "Validation Epoch 6: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6853\n",
      "Epoch 6: Train Metric=0.1788, Val Metric=0.1614, Val Loss=27.1785\n",
      "Saving model with Val Loss=27.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.29it/s]\n",
      "Validation Epoch 7: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6975\n",
      "Epoch 7: Train Metric=0.1599, Val Metric=0.1529, Val Loss=25.7442\n",
      "Saving model with Val Loss=25.7442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.29it/s]\n",
      "Validation Epoch 8: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7028\n",
      "Epoch 8: Train Metric=0.1520, Val Metric=0.1634, Val Loss=27.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.22it/s]\n",
      "Validation Epoch 9: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7223\n",
      "Epoch 9: Train Metric=0.1410, Val Metric=0.1649, Val Loss=27.7441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.24it/s]\n",
      "Validation Epoch 10: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.44it/s]\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_84\\2904733188.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(output_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7277\n",
      "Epoch 10: Train Metric=0.1311, Val Metric=0.1825, Val Loss=30.6929\n",
      "Early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████| 851/851 [00:15<00:00, 53.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6439\n",
      "Test MSE: 0.5384\n",
      "Test Accuracy for task: regression at sequence length 237 pretrain model transformer_model_1000: 0.5384\n",
      "Training model for task: regression, sequence length: 237, pretrain model: orchid_model_tmp_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.30it/s]\n",
      "Validation Epoch 1: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5105\n",
      "Epoch 1: Train Metric=0.7290, Val Metric=0.6152, Val Loss=103.3124\n",
      "Saving model with Val Loss=103.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:11<00:00,  9.32it/s]\n",
      "Validation Epoch 2: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5792\n",
      "Epoch 2: Train Metric=0.4545, Val Metric=0.3377, Val Loss=56.7421\n",
      "Saving model with Val Loss=56.7421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.31it/s]\n",
      "Validation Epoch 3: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6281\n",
      "Epoch 3: Train Metric=0.3121, Val Metric=0.3453, Val Loss=58.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.29it/s]\n",
      "Validation Epoch 4: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6572\n",
      "Epoch 4: Train Metric=0.2576, Val Metric=0.2113, Val Loss=35.5221\n",
      "Saving model with Val Loss=35.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.29it/s]\n",
      "Validation Epoch 5: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6830\n",
      "Epoch 5: Train Metric=0.2071, Val Metric=0.2243, Val Loss=37.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.21it/s]\n",
      "Validation Epoch 6: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7259\n",
      "Epoch 6: Train Metric=0.1703, Val Metric=0.1795, Val Loss=30.1696\n",
      "Saving model with Val Loss=30.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:11<00:00,  9.33it/s]\n",
      "Validation Epoch 7: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7237\n",
      "Epoch 7: Train Metric=0.1482, Val Metric=0.1458, Val Loss=24.5205\n",
      "Saving model with Val Loss=24.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.28it/s]\n",
      "Validation Epoch 8: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7389\n",
      "Epoch 8: Train Metric=0.1336, Val Metric=0.1889, Val Loss=31.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.28it/s]\n",
      "Validation Epoch 9: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7451\n",
      "Epoch 9: Train Metric=0.1268, Val Metric=0.1481, Val Loss=24.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.29it/s]\n",
      "Validation Epoch 10: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7461\n",
      "Epoch 10: Train Metric=0.1195, Val Metric=0.1447, Val Loss=24.3488\n",
      "Saving model with Val Loss=24.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.13it/s]\n",
      "Validation Epoch 11: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7453\n",
      "Epoch 11: Train Metric=0.1108, Val Metric=0.2078, Val Loss=34.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.31it/s]\n",
      "Validation Epoch 12: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7424\n",
      "Epoch 12: Train Metric=0.1077, Val Metric=0.1597, Val Loss=26.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.29it/s]\n",
      "Validation Epoch 13: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7495\n",
      "Epoch 13: Train Metric=0.1028, Val Metric=0.1217, Val Loss=20.5251\n",
      "Saving model with Val Loss=20.5251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.31it/s]\n",
      "Validation Epoch 14: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7576\n",
      "Epoch 14: Train Metric=0.0921, Val Metric=0.1247, Val Loss=21.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.28it/s]\n",
      "Validation Epoch 15: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7605\n",
      "Epoch 15: Train Metric=0.0886, Val Metric=0.1729, Val Loss=29.1086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.19it/s]\n",
      "Validation Epoch 16: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7591\n",
      "Epoch 16: Train Metric=0.0845, Val Metric=0.1175, Val Loss=19.8137\n",
      "Saving model with Val Loss=19.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.21it/s]\n",
      "Validation Epoch 17: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7577\n",
      "Epoch 17: Train Metric=0.0805, Val Metric=0.1104, Val Loss=18.5888\n",
      "Saving model with Val Loss=18.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.24it/s]\n",
      "Validation Epoch 18: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7690\n",
      "Epoch 18: Train Metric=0.0798, Val Metric=0.0988, Val Loss=16.6726\n",
      "Saving model with Val Loss=16.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.30it/s]\n",
      "Validation Epoch 19: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7691\n",
      "Epoch 19: Train Metric=0.0748, Val Metric=0.1017, Val Loss=17.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:12<00:00,  9.29it/s]\n",
      "Validation Epoch 20: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7732\n",
      "Epoch 20: Train Metric=0.0745, Val Metric=0.1198, Val Loss=20.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████| 851/851 [00:28<00:00, 29.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6712\n",
      "Test MSE: 0.2218\n",
      "Test Accuracy for task: regression at sequence length 237 pretrain model orchid_model_tmp_1000: 0.2218\n",
      "Training model for task: classification, sequence length: 998, pretrain model: transformer_model_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:42<00:00,  1.67it/s]\n",
      "Validation Epoch 1: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Metric=0.5090, Val Metric=0.5311, Val Loss=65.1677\n",
      "Saving model with Val Loss=65.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 2: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Metric=0.5282, Val Metric=0.5362, Val Loss=64.7392\n",
      "Saving model with Val Loss=64.7392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 3: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Metric=0.5326, Val Metric=0.5366, Val Loss=64.6395\n",
      "Saving model with Val Loss=64.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:42<00:00,  1.67it/s]\n",
      "Validation Epoch 4: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Metric=0.5362, Val Metric=0.5327, Val Loss=64.7626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 5: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Metric=0.5389, Val Metric=0.5404, Val Loss=64.1614\n",
      "Saving model with Val Loss=64.1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 6: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Metric=0.5418, Val Metric=0.5431, Val Loss=63.9272\n",
      "Saving model with Val Loss=63.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 7: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Metric=0.5445, Val Metric=0.5385, Val Loss=64.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.68it/s]\n",
      "Validation Epoch 8: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Metric=0.5491, Val Metric=0.5487, Val Loss=63.3616\n",
      "Saving model with Val Loss=63.3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 9: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Metric=0.5584, Val Metric=0.5601, Val Loss=62.4277\n",
      "Saving model with Val Loss=62.4277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:42<00:00,  1.67it/s]\n",
      "Validation Epoch 10: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Metric=0.5727, Val Metric=0.5824, Val Loss=60.2736\n",
      "Saving model with Val Loss=60.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.68it/s]\n",
      "Validation Epoch 11: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Metric=0.5881, Val Metric=0.6031, Val Loss=58.5552\n",
      "Saving model with Val Loss=58.5552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:42<00:00,  1.67it/s]\n",
      "Validation Epoch 12: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Metric=0.6013, Val Metric=0.6125, Val Loss=57.7705\n",
      "Saving model with Val Loss=57.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.68it/s]\n",
      "Validation Epoch 13: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Metric=0.6091, Val Metric=0.6172, Val Loss=57.2446\n",
      "Saving model with Val Loss=57.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 14: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Metric=0.6149, Val Metric=0.6193, Val Loss=57.0767\n",
      "Saving model with Val Loss=57.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:42<00:00,  1.67it/s]\n",
      "Validation Epoch 15: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Metric=0.6192, Val Metric=0.6202, Val Loss=56.8476\n",
      "Saving model with Val Loss=56.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 16: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Metric=0.6222, Val Metric=0.6295, Val Loss=55.7370\n",
      "Saving model with Val Loss=55.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 17: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Metric=0.6260, Val Metric=0.6311, Val Loss=55.4669\n",
      "Saving model with Val Loss=55.4669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 18: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Metric=0.6290, Val Metric=0.6327, Val Loss=55.4340\n",
      "Saving model with Val Loss=55.4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 19: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Metric=0.6320, Val Metric=0.6357, Val Loss=54.9983\n",
      "Saving model with Val Loss=54.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|█████████████████████████████████████████████████████████████| 271/271 [02:41<00:00,  1.67it/s]\n",
      "Validation Epoch 20: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:08<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Metric=0.6343, Val Metric=0.6329, Val Loss=55.5137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████████████████| 17/17 [00:02<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6204\n",
      "Test Accuracy for task: classification at sequence length 998 pretrain model transformer_model_1000: 0.6204\n",
      "Training model for task: classification, sequence length: 998, pretrain model: orchid_model_tmp_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 1: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Metric=0.6218, Val Metric=0.6774, Val Loss=51.0519\n",
      "Saving model with Val Loss=51.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 2: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Metric=0.6846, Val Metric=0.6936, Val Loss=47.9978\n",
      "Saving model with Val Loss=47.9978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 3: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Metric=0.6974, Val Metric=0.7055, Val Loss=46.5040\n",
      "Saving model with Val Loss=46.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:36<00:00,  1.69s/it]\n",
      "Validation Epoch 4: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Metric=0.7050, Val Metric=0.7096, Val Loss=45.9139\n",
      "Saving model with Val Loss=45.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 5: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Metric=0.7104, Val Metric=0.7121, Val Loss=45.5777\n",
      "Saving model with Val Loss=45.5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:36<00:00,  1.69s/it]\n",
      "Validation Epoch 6: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Metric=0.7142, Val Metric=0.7134, Val Loss=45.2315\n",
      "Saving model with Val Loss=45.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 7: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Metric=0.7191, Val Metric=0.7124, Val Loss=45.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 8: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Metric=0.7223, Val Metric=0.7173, Val Loss=45.0835\n",
      "Saving model with Val Loss=45.0835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 271/271 [07:36<00:00,  1.69s/it]\n",
      "Validation Epoch 9: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Metric=0.7262, Val Metric=0.7178, Val Loss=44.9766\n",
      "Saving model with Val Loss=44.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 271/271 [07:36<00:00,  1.69s/it]\n",
      "Validation Epoch 10: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Metric=0.7304, Val Metric=0.7159, Val Loss=45.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 271/271 [07:37<00:00,  1.69s/it]\n",
      "Validation Epoch 11: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Metric=0.7333, Val Metric=0.7180, Val Loss=45.3723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 271/271 [07:36<00:00,  1.69s/it]\n",
      "Validation Epoch 12: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:07<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Metric=0.7366, Val Metric=0.7159, Val Loss=45.4771\n",
      "Early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6988\n",
      "Test Accuracy for task: classification at sequence length 998 pretrain model orchid_model_tmp_1000: 0.6988\n",
      "Training model for task: regression, sequence length: 237, pretrain model: transformer_model_2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.33it/s]\n",
      "Validation Epoch 1: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5013\n",
      "Epoch 1: Train Metric=0.7227, Val Metric=0.5781, Val Loss=97.0794\n",
      "Saving model with Val Loss=97.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.25it/s]\n",
      "Validation Epoch 2: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5989\n",
      "Epoch 2: Train Metric=0.3983, Val Metric=0.3018, Val Loss=50.7142\n",
      "Saving model with Val Loss=50.7142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.33it/s]\n",
      "Validation Epoch 3: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6662\n",
      "Epoch 3: Train Metric=0.2804, Val Metric=0.2309, Val Loss=38.7789\n",
      "Saving model with Val Loss=38.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.29it/s]\n",
      "Validation Epoch 4: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7118\n",
      "Epoch 4: Train Metric=0.2008, Val Metric=0.1609, Val Loss=27.0328\n",
      "Saving model with Val Loss=27.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.30it/s]\n",
      "Validation Epoch 5: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7392\n",
      "Epoch 5: Train Metric=0.1604, Val Metric=0.2441, Val Loss=41.0409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.23it/s]\n",
      "Validation Epoch 6: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7517\n",
      "Epoch 6: Train Metric=0.1412, Val Metric=0.1253, Val Loss=21.0734\n",
      "Saving model with Val Loss=21.0734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.32it/s]\n",
      "Validation Epoch 7: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7545\n",
      "Epoch 7: Train Metric=0.1276, Val Metric=0.1169, Val Loss=19.6826\n",
      "Saving model with Val Loss=19.6826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.28it/s]\n",
      "Validation Epoch 8: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 54.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7676\n",
      "Epoch 8: Train Metric=0.1177, Val Metric=0.1143, Val Loss=19.2058\n",
      "Saving model with Val Loss=19.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.21it/s]\n",
      "Validation Epoch 9: 100%|████████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7691\n",
      "Epoch 9: Train Metric=0.1130, Val Metric=0.1480, Val Loss=24.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.29it/s]\n",
      "Validation Epoch 10: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7784\n",
      "Epoch 10: Train Metric=0.1019, Val Metric=0.1412, Val Loss=23.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.31it/s]\n",
      "Validation Epoch 11: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7746\n",
      "Epoch 11: Train Metric=0.0973, Val Metric=0.1104, Val Loss=18.5818\n",
      "Saving model with Val Loss=18.5818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.22it/s]\n",
      "Validation Epoch 12: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7774\n",
      "Epoch 12: Train Metric=0.0918, Val Metric=0.0862, Val Loss=14.5066\n",
      "Saving model with Val Loss=14.5066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.33it/s]\n",
      "Validation Epoch 13: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7759\n",
      "Epoch 13: Train Metric=0.0840, Val Metric=0.0880, Val Loss=14.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.20it/s]\n",
      "Validation Epoch 14: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7808\n",
      "Epoch 14: Train Metric=0.0798, Val Metric=0.1425, Val Loss=23.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|█████████████████████████████████████████████████████████████| 671/671 [00:50<00:00, 13.30it/s]\n",
      "Validation Epoch 15: 100%|███████████████████████████████████████████████████████████| 168/168 [00:03<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7807\n",
      "Epoch 15: Train Metric=0.0777, Val Metric=0.1328, Val Loss=22.3442\n",
      "Early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████| 851/851 [00:15<00:00, 53.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6728\n",
      "Test MSE: 0.2283\n",
      "Test Accuracy for task: regression at sequence length 237 pretrain model transformer_model_2000: 0.2283\n",
      "Training model for task: regression, sequence length: 237, pretrain model: orchid_model_tmp_2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.08it/s]\n",
      "Validation Epoch 1: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.3363\n",
      "Epoch 1: Train Metric=0.7446, Val Metric=0.6123, Val Loss=102.8506\n",
      "Saving model with Val Loss=102.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.11it/s]\n",
      "Validation Epoch 2: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5490\n",
      "Epoch 2: Train Metric=0.4765, Val Metric=0.3955, Val Loss=66.4819\n",
      "Saving model with Val Loss=66.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.12it/s]\n",
      "Validation Epoch 3: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.5837\n",
      "Epoch 3: Train Metric=0.3043, Val Metric=0.3101, Val Loss=52.1467\n",
      "Saving model with Val Loss=52.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.17it/s]\n",
      "Validation Epoch 4: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6655\n",
      "Epoch 4: Train Metric=0.2442, Val Metric=0.2507, Val Loss=42.1074\n",
      "Saving model with Val Loss=42.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:14<00:00,  9.02it/s]\n",
      "Validation Epoch 5: 100%|████████████████████████████████████████████████████████████| 168/168 [00:06<00:00, 27.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6920\n",
      "Epoch 5: Train Metric=0.2055, Val Metric=0.2510, Val Loss=42.2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:14<00:00,  9.04it/s]\n",
      "Validation Epoch 6: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6811\n",
      "Epoch 6: Train Metric=0.1754, Val Metric=0.1883, Val Loss=31.6733\n",
      "Saving model with Val Loss=31.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.13it/s]\n",
      "Validation Epoch 7: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7044\n",
      "Epoch 7: Train Metric=0.1633, Val Metric=0.1574, Val Loss=26.4437\n",
      "Saving model with Val Loss=26.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.16it/s]\n",
      "Validation Epoch 8: 100%|████████████████████████████████████████████████████████████| 168/168 [00:06<00:00, 27.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7163\n",
      "Epoch 8: Train Metric=0.1391, Val Metric=0.2320, Val Loss=39.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.08it/s]\n",
      "Validation Epoch 9: 100%|████████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7397\n",
      "Epoch 9: Train Metric=0.1272, Val Metric=0.1226, Val Loss=20.6090\n",
      "Saving model with Val Loss=20.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.14it/s]\n",
      "Validation Epoch 10: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7425\n",
      "Epoch 10: Train Metric=0.1214, Val Metric=0.1215, Val Loss=20.4488\n",
      "Saving model with Val Loss=20.4488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.09it/s]\n",
      "Validation Epoch 11: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7519\n",
      "Epoch 11: Train Metric=0.1134, Val Metric=0.1153, Val Loss=19.4121\n",
      "Saving model with Val Loss=19.4121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.15it/s]\n",
      "Validation Epoch 12: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7542\n",
      "Epoch 12: Train Metric=0.1078, Val Metric=0.1813, Val Loss=30.5292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.07it/s]\n",
      "Validation Epoch 13: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7559\n",
      "Epoch 13: Train Metric=0.1061, Val Metric=0.1490, Val Loss=25.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|█████████████████████████████████████████████████████████████| 671/671 [01:13<00:00,  9.07it/s]\n",
      "Validation Epoch 14: 100%|███████████████████████████████████████████████████████████| 168/168 [00:05<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.7483\n",
      "Epoch 14: Train Metric=0.0940, Val Metric=0.1986, Val Loss=33.4089\n",
      "Early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████| 851/851 [00:30<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: 0.6647\n",
      "Test MSE: 0.3649\n",
      "Test Accuracy for task: regression at sequence length 237 pretrain model orchid_model_tmp_2000: 0.3649\n",
      "Training model for task: classification, sequence length: 1632, pretrain model: transformer_model_2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:39<00:00,  1.69s/it]\n",
      "Validation Epoch 1: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Metric=0.5135, Val Metric=0.5352, Val Loss=64.8405\n",
      "Saving model with Val Loss=64.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.69s/it]\n",
      "Validation Epoch 2: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Metric=0.5294, Val Metric=0.5371, Val Loss=64.7088\n",
      "Saving model with Val Loss=64.7088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.69s/it]\n",
      "Validation Epoch 3: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Metric=0.5335, Val Metric=0.5374, Val Loss=64.6116\n",
      "Saving model with Val Loss=64.6116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.69s/it]\n",
      "Validation Epoch 4: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Metric=0.5369, Val Metric=0.5388, Val Loss=64.3397\n",
      "Saving model with Val Loss=64.3397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.69s/it]\n",
      "Validation Epoch 5: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Metric=0.5398, Val Metric=0.5393, Val Loss=64.2780\n",
      "Saving model with Val Loss=64.2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.69s/it]\n",
      "Validation Epoch 6: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Metric=0.5430, Val Metric=0.5431, Val Loss=63.8898\n",
      "Saving model with Val Loss=63.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 7: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Metric=0.5468, Val Metric=0.5494, Val Loss=63.3194\n",
      "Saving model with Val Loss=63.3194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.68s/it]\n",
      "Validation Epoch 8: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Metric=0.5543, Val Metric=0.5581, Val Loss=62.4075\n",
      "Saving model with Val Loss=62.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 9: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Metric=0.5671, Val Metric=0.5765, Val Loss=60.9523\n",
      "Saving model with Val Loss=60.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 10: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Metric=0.5817, Val Metric=0.5892, Val Loss=59.7149\n",
      "Saving model with Val Loss=59.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 11: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Metric=0.5925, Val Metric=0.6000, Val Loss=58.8642\n",
      "Saving model with Val Loss=58.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 12: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Metric=0.6024, Val Metric=0.6163, Val Loss=57.1157\n",
      "Saving model with Val Loss=57.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 13: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Metric=0.6108, Val Metric=0.6171, Val Loss=57.0837\n",
      "Saving model with Val Loss=57.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 14: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Metric=0.6165, Val Metric=0.6218, Val Loss=56.5471\n",
      "Saving model with Val Loss=56.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 15: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Metric=0.6197, Val Metric=0.6256, Val Loss=56.3287\n",
      "Saving model with Val Loss=56.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 16: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Metric=0.6230, Val Metric=0.6232, Val Loss=56.3892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 17: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Metric=0.6246, Val Metric=0.6298, Val Loss=55.7618\n",
      "Saving model with Val Loss=55.7618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 18: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Metric=0.6277, Val Metric=0.6302, Val Loss=55.7102\n",
      "Saving model with Val Loss=55.7102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:38<00:00,  1.68s/it]\n",
      "Validation Epoch 19: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Metric=0.6289, Val Metric=0.6271, Val Loss=56.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|█████████████████████████████████████████████████████████████| 272/272 [07:37<00:00,  1.68s/it]\n",
      "Validation Epoch 20: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:16<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Metric=0.6312, Val Metric=0.6274, Val Loss=56.3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████████████████| 17/17 [00:03<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6135\n",
      "Test Accuracy for task: classification at sequence length 1632 pretrain model transformer_model_2000: 0.6135\n",
      "Training model for task: classification, sequence length: 1632, pretrain model: orchid_model_tmp_2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 1: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Metric=0.6283, Val Metric=0.6748, Val Loss=50.9122\n",
      "Saving model with Val Loss=50.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 2: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Metric=0.6833, Val Metric=0.6901, Val Loss=48.6743\n",
      "Saving model with Val Loss=48.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 3: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Metric=0.6955, Val Metric=0.7050, Val Loss=46.4871\n",
      "Saving model with Val Loss=46.4871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 4: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Metric=0.7026, Val Metric=0.7087, Val Loss=46.0114\n",
      "Saving model with Val Loss=46.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 5: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Metric=0.7075, Val Metric=0.7102, Val Loss=45.7737\n",
      "Saving model with Val Loss=45.7737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 6: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Metric=0.7120, Val Metric=0.7129, Val Loss=45.3466\n",
      "Saving model with Val Loss=45.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 7: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Metric=0.7165, Val Metric=0.7150, Val Loss=45.3227\n",
      "Saving model with Val Loss=45.3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:24<00:00,  1.41s/it]\n",
      "Validation Epoch 8: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Metric=0.7198, Val Metric=0.7166, Val Loss=44.9500\n",
      "Saving model with Val Loss=44.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████████████████████████████████████████████████████████| 272/272 [06:24<00:00,  1.41s/it]\n",
      "Validation Epoch 9: 100%|██████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Metric=0.7243, Val Metric=0.7046, Val Loss=46.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|█████████████████████████████████████████████████████████████| 272/272 [06:25<00:00,  1.42s/it]\n",
      "Validation Epoch 10: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Metric=0.7274, Val Metric=0.7165, Val Loss=44.7936\n",
      "Saving model with Val Loss=44.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|█████████████████████████████████████████████████████████████| 272/272 [06:24<00:00,  1.41s/it]\n",
      "Validation Epoch 11: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Metric=0.7304, Val Metric=0.7186, Val Loss=44.7540\n",
      "Saving model with Val Loss=44.7540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|█████████████████████████████████████████████████████████████| 272/272 [06:23<00:00,  1.41s/it]\n",
      "Validation Epoch 12: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Metric=0.7340, Val Metric=0.7194, Val Loss=44.9539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|█████████████████████████████████████████████████████████████| 272/272 [06:26<00:00,  1.42s/it]\n",
      "Validation Epoch 13: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Metric=0.7367, Val Metric=0.7175, Val Loss=45.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|█████████████████████████████████████████████████████████████| 272/272 [06:26<00:00,  1.42s/it]\n",
      "Validation Epoch 14: 100%|█████████████████████████████████████████████████████████████| 68/68 [00:14<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Metric=0.7391, Val Metric=0.7163, Val Loss=46.1363\n",
      "Early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████████████████| 17/17 [00:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6994\n",
      "Test Accuracy for task: classification at sequence length 1632 pretrain model orchid_model_tmp_2000: 0.6994\n",
      "{'seq_len': 1000, 'task': 'regression', 'pretrained_model': 'transformer_model', 'test_accuracy': 0.5384143093188811}\n",
      "{'seq_len': 1000, 'task': 'regression', 'pretrained_model': 'orchid_model_tmp', 'test_accuracy': 0.2217750140031325}\n",
      "{'seq_len': 1000, 'task': 'classification', 'pretrained_model': 'transformer_model', 'test_accuracy': 0.6203518980326961}\n",
      "{'seq_len': 1000, 'task': 'classification', 'pretrained_model': 'orchid_model_tmp', 'test_accuracy': 0.6988085342200056}\n",
      "{'seq_len': 2000, 'task': 'regression', 'pretrained_model': 'transformer_model', 'test_accuracy': 0.2282922454543786}\n",
      "{'seq_len': 2000, 'task': 'regression', 'pretrained_model': 'orchid_model_tmp', 'test_accuracy': 0.36485722032385043}\n",
      "{'seq_len': 2000, 'task': 'classification', 'pretrained_model': 'transformer_model', 'test_accuracy': 0.6134663341645885}\n",
      "{'seq_len': 2000, 'task': 'classification', 'pretrained_model': 'orchid_model_tmp', 'test_accuracy': 0.6994389027431421}\n"
     ]
    }
   ],
   "source": [
    "# Iterate over different configurations and record metrics\n",
    "seq_lengths = [1000, 2000]\n",
    "tasks = [\"regression\",\"classification\"]\n",
    "pretrained_model_paths = [\"transformer_model\", \"orchid_model_tmp\"]\n",
    "metrics = []\n",
    "\n",
    "for seq_len in seq_lengths:\n",
    "    for task in tasks:\n",
    "        for pretrained_path in pretrained_model_paths:\n",
    "            output_path = f\"{pretrained_path}_{task}_{seq_len}_1\"\n",
    "            test_accuracy = train_and_test(\n",
    "                task_type=task,\n",
    "                train_data=fluorescence_input_label_pairs[\"train\"] if task == \"regression\" else secondary_structure_input_label_pairs[\"train\"],\n",
    "                val_data=fluorescence_input_label_pairs[\"val\"] if task == \"regression\" else secondary_structure_input_label_pairs[\"val\"],\n",
    "                test_data=fluorescence_input_label_pairs[\"test\"] if task == \"regression\" else secondary_structure_input_label_pairs[\"test\"],\n",
    "                seq_len=seq_len,\n",
    "                vocab=vocab,\n",
    "                model_class=BertForMaskedLM if pretrained_path == \"transformer_model\" else OrchidBERT,\n",
    "                pretrained_model_path=f\"{pretrained_path}_{seq_len}\",\n",
    "                output_model_path=output_path,\n",
    "                num_targets=1 if task == \"regression\" else 3,\n",
    "                skip = [\"transformer_model_classification_1000\",\"orchid_model_tmp_classification_1000\",\n",
    "                        \"transformer_model_classification_2000\",\"orchid_model_tmp_classification_2000\"]\n",
    "            )\n",
    "            metrics.append({\n",
    "                \"seq_len\": seq_len,\n",
    "                \"task\": task,\n",
    "                \"pretrained_model\": pretrained_path,\n",
    "                \"test_accuracy\": test_accuracy\n",
    "            })\n",
    "\n",
    "# Print all metrics\n",
    "for metric in metrics:\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0a202-a9ae-465d-9d05-d832bf17b7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
